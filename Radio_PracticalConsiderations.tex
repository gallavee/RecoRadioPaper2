In this section we offer some discussion on ideas that allow the application of the model proposed in this paper to a real-world system serving a large number of users.

The playlist is constructed sequentially by picking the next track using the ranking induced by $\hat{r}_m$ from (\ref{eq:PredictionApproximation}). However, in practice we first apply two important heuristics. First, since it is impractical to consider the tens of millions of tracks in the Groove music catalog, we first pre-compute a candidate list of $M \approx 1,000$ tracks for each possible seed artist.
The candidate list for an artist $a^*$ consists of $a^*$'s tracks and tracks from artists similar to $a^*$. Second, we define a Boltzmann distribution over the $m=1 \dots M$ tracks with each candidate track having a probability given by $p_m=\frac{e^{s \cdot \hat{r}_m}}{\sum_{i=1}^M e^{s \cdot \hat{r}_i}}$, where $s$ is a tunable parameter. The next track is chosen randomly with probability $p_m$. This scheme ensures a degree of diversity, controlled by $s$, between multiple instances of similar playlists. This type of randomization also acts as an exploration mechanism, allowing labels to be collected from areas where the model is less certain. This reduces the feedback loop effect when learning future models based on user interactions with the system.



An advantage of the Bayesian setup described in this work is that it is fairly straightforward to adjust the model parameters in an online fashion. For example, consider the scenario where a playlist user skips several tracks in a row. Our approach could be extended to update the user parameter vector given these additional explicit negatives, before computing the next track selection.

\noam{I think the discussion about hyper-params better fit in the model section. However, I prefer to drop it for now because I don't think it strengthen the paper.}
%When setting hyper-parameters, we fixed them to $\alpha=\beta=1$ as we observed that results are robust to this setting. For completeness, hyper-parameters can also be tuned with cross-validation. \GL{This should be stated in the model section if it pertains to the experiments. Though, i dont think it has too much added value or insight to justify being included at all}
Finally, our model is designed for implicit feedback signals, as these are more common in commercial settings, hence the use of binary labels. However, in some scenarios explicit user ratings are known. Support for such scenarios can be achieved by modifying the likelihood term of our model (in (\ref{eq:likelihood})) and re-deriving the update equations.
\GL{is anything missing here? some discussion of the settings of the hyper parameters and the "active" range of the logistic function as per ulrich's suggestion perhaps?} \noam{This can go on forever... :)  I think these good points suffice.} \SBE{I think the hyperparameter discussion is important, and tried to keep it short.}